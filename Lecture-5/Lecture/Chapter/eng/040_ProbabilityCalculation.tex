\subsection{Probability Calculation}

\begin{frame}{Universal Hashing}{Probability Calculation}
  \begin{columns}
    \begin{column}{0.65\textwidth}
      \begin{itemize}
        \item
          Theorethical space $\Omega$ with basic events $e \in \Omega$
        \item
          Each event $e$ has it's probability with
          \[\sum \mathbb{P}(e) = 1 \mid e \in \Omega\]
        \item
          The probability for a subspace of events $E \subseteq \Omega$ is
          \[\mathbb{P}(E) = \sum \mathbb{P}(e) \mid e \in E\]
      \end{itemize}
    \end{column}
    \begin{column}{0.35\textwidth}
      \begin{table}[!h]
        \caption{Throwing a dice}
        \label{tab:probabilities:rolling_dice}
        \begin{tabularx}{0.5\linewidth}{c|c}
          $e$ & $\mathbb{P}(e)$\\
          \midrule
          1 & $\sfrac{1}{6}$\\
          2 & $\sfrac{1}{6}$\\
          3 & $\sfrac{1}{6}$\\
          4 & $\sfrac{1}{6}$\\
          5 & $\sfrac{1}{6}$\\
          6 & $\sfrac{1}{6}$\\
        \end{tabularx}
      \end{table}
    \end{column}
  \end{columns}
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \begin{columns}
    \begin{column}{0.65\linewidth}
      \textbf{Example:}
      \begin{itemize}
        \item
          Rolling a dice twice ($\Omega = \{1,\dots,6\}^2$)
        \item
          Each event $e_{(i,\,j)} \in \Omega$ has the probability
          $\mathbb{P}(e) = \sfrac{1}{36}$
        \item
          $X = i + j$ is the eye number
        \item
          \begin{math}
            E = \{e_{(i,\,j)} \in \Omega
              \mid i + j \;\mathrm{mod}\; 2 = 0\}
          \end{math}
      \end{itemize}
    \end{column}
    \begin{column}{0.35\linewidth}
      \begin{table}[!h]
        \caption{Throwing a dice twice}
        \label{tab:probabilities_rolling_dice_twice}
        \begin{tabularx}{0.8\linewidth}{c|c}
          $e_{(i,\,j)}$ & $\mathbb{P}(e_{(i,\,j)})$\\
          \midrule
          $(1, 1)$ & $\sfrac{1}{36}$\\
          $(1, 2)$ & $\sfrac{1}{36}$\\
          $(1, 3)$ & $\sfrac{1}{36}$\\
          $\dots$ & $\dots$\\
          $(6, 5)$ & $\sfrac{1}{36}$\\
          $(6, 6)$ & $\sfrac{1}{36}$\\
        \end{tabularx}
      \end{table}
    \end{column}
  \end{columns}
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \begin{columns}
    \begin{column}{0.55\linewidth}
      \textbf{Example:}
      \begin{itemize}
        \item
          We define: $X$ is the result variable of the experiment
        \item
          We can reduce the result set by creating preconditions for our
          result variable $X$\\[0.5em]
          Examples:
          \begin{itemize}
            \item
              $\mathbb{P}(X = 2) = $
            \item
              $\mathbb{P}(X = 4) = $
          \end{itemize}
      \end{itemize}
    \end{column}
    \begin{column}{0.45\linewidth}
      \begin{table}[!h]
        \caption{Throwing a dice twice}
        \label{tab:probabilities:rolling_dice_twice2}
        \begin{tabularx}{0.95\linewidth}{c|cc}
          $e_{(i,\,j)}$ & $\mathbb{P}(e_{(i,\,j)})$ & $X = i + j$\\
          \midrule
          $(1, 1)$ & $\sfrac{1}{36}$ & 2\\
          $(1, 2)$ & $\sfrac{1}{36}$ & 3\\
          $(1, 3)$ & $\sfrac{1}{36}$ & 4\\
          $\dots$ & $\dots$ & $\dots$\\
          $(6, 5)$ & $\sfrac{1}{36}$ & 11\\
          $(6, 6)$ & $\sfrac{1}{36}$ & 12\\
        \end{tabularx}
      \end{table}
    \end{column}
  \end{columns}
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \begin{columns}
    \begin{column}{0.55\linewidth}
      \textbf{Example:}
      \begin{itemize}
        \item
          $E = \{e_{(i,\,j)} \in \Omega
          \mid X \;\mathrm{mod}\; 2 = 0\}$\\
          $\mathbb{P}(E) =$
      \end{itemize}
    \end{column}
    \begin{column}{0.45\linewidth}
      \begin{table}[!h]
        \caption{Throwing a dice twice}
        \label{tab:probabilities:rolling_dice_twice3}
        \begin{tabularx}{0.95\linewidth}{c|cc}
          $e_{(i,\,j)}$ & $\mathbb{P}(e_{(i,\,j)})$ & $X = i + j$\\
          \midrule
          $(1, 1)$ & $\sfrac{1}{36}$ & 2\\
          $(1, 2)$ & $\sfrac{1}{36}$ & 3\\
          $(1, 3)$ & $\sfrac{1}{36}$ & 4\\
          $\dots$ & $\dots$ & $\dots$\\
          $(6, 5)$ & $\sfrac{1}{36}$ & 11\\
          $(6, 6)$ & $\sfrac{1}{36}$ & 12\\
        \end{tabularx}
      \end{table}
    \end{column}
  \end{columns}
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \textbf{Expected value:}
  \[\mathbb{E}[X]
    = \sum_{X \in \mathbb{X}} \left(k \cdot \mathbb{P}(X = k)\right)\]
  \begin{itemize}
    \item
      The weighted average of all possible resulting values $\mathbb{X}$
    \item
      The weight factor is the result value $X$ itself
  \end{itemize}
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \vspace*{-1.5em}
  \begin{table}[!h]
    \caption{Throwing a dice once}
    \label{tab:probabilities:value_rolling_dice_once}
    \begin{tabularx}{0.25\linewidth}{c|cc}
      $X_1 = i$ & $\mathbb{P}(X_1)$\\
      \midrule
      1 & $\sfrac{1}{6}$\\
      2 & $\sfrac{1}{6}$\\
      3 & $\sfrac{1}{6}$\\
      4 & $\sfrac{1}{6}$\\
      5 & $\sfrac{1}{6}$\\
      6 & $\sfrac{1}{6}$\\
    \end{tabularx}
  \end{table}
  Throwing the dice once:
  \[\mathbb{E}[X_1] = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6}
    + \dots + 6 \cdot \frac{1}{6} = 3.5\]
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \vspace*{-1.5em}
  \begin{table}[!h]
    \caption{Throwing a dice twice}
    \label{tab:probabilities:value_rolling_dice_twice}
    \begin{tabularx}{0.275\linewidth}{c|cc}
      $X_2 = i + j$ & $\mathbb{P}(X_2)$\\
      \midrule
      2 & $\sfrac{1}{36}$\\
      3 & $\sfrac{2}{36}$\\
      4 & $\sfrac{3}{36}$\\
      $\dots$ & $\dots$\\
      11 & $\sfrac{2}{36}$\\
      12 & $\sfrac{1}{36}$\\
    \end{tabularx}
  \end{table}
  Throwing the dice twice:
  \[\mathbb{E}[X_2] = 2 \cdot \frac{1}{36} + 3 \cdot \frac{2}{36}
    + \dots + 12 \cdot \frac{1}{36} = 7\]
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \textbf{Sum of expected values:}
  For independent (discrete) result variables $X_1,\dots,X_n$ we can write:
    \[\mathbb{E}\left[X_1+\dots+X_n\right]
      = \mathbb{E}[X_1] + \dots + \mathbb{E}[X_n]\]
  \textbf{Example:} Throwing two dice
  \begin{itemize}
    \item
      $X_a$: Expected number of eyes dice $a$: $\mathbb{E}[X_a] = 3.5$
    \item
      $X_b$: Expected number of eyes dice $b$: $\mathbb{E}[X_b] = 3.5$
    \item
      $X = X_a + X_b$: Expected total number of eyes:
      \[\mathbb{E}[X]
        = \mathbb{E}[X_a + X_b]
        = \mathbb{E}[X_a] + \mathbb{E}[X_b] = 3.5 + 3.5 = 7\]
  \end{itemize}
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \begin{block}{Corollary:}
    The probability of the event $E$ is $p = \mathbb{P}(E)$.
    Let $X$ be the occurences of the event $E$ and $n$ be the number
    of executions.
    \[\mathbb{E}[X] = n \cdot \mathbb{P}(E) = n \cdot p\]
  \end{block}
  \begin{example}[Rolling the dice 60 times:]
    \[\mathbb{E}\left[\text{number of 6}\right] = \frac{1}{6} \cdot 60 = 10\]
  \end{example}
\end{frame}

%-------------------------------------------------------------------------------

\begin{frame}{Universal Hashing}{Probability Calculation}
  \begin{proof}[Proof Corollary:]
    Indicator variable: $X_i$\\
    \vspace*{-1.5em}
    \begin{align*}
      X_i &=
        \left\lbrace
          \begin{array}{ll}
            1, & \text{if event occurs}\\
            0, & \text{else}
          \end{array}
        \right. \hspace{1.5em}
        \Rightarrow \; X = \sum_{i=1}^{n} X_i
    \end{align*}
    \vspace*{-1.0em}
    \begin{align*}
      \mathbb{E}[X_i]
        &= \; 0 \cdot \mathbb{P}(X_i = 0) + 1 \cdot \mathbb{P}(X_i = 1)\\
      {} &= \; \mathbb{P}(X_i = 1) = p\\[0.5em]
      \mathbb{E}[X] &= \mathbb{E}\left[\sum_{i=1}^{n} X_i\right]
        = \sum_{i=1}^{n} \mathbb{E}[X_i]
        \stackrel{\text{def. $E$-value}}{=}
        \sum_{i=1}^{n} p = n \cdot p
    \end{align*}
    \qedhere
  \end{proof}
\end{frame}